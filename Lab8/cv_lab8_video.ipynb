{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_r0j8Xuqsga"
      },
      "source": [
        "# Computer vision - Lab 8\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVWBS5p-r5j9"
      },
      "source": [
        "## Agenda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd2FzMMMr9kr"
      },
      "source": [
        "- introduction to the camera and its parameters\n",
        "- advanced image processing techniques,\n",
        "- understanding the scene as schemes, objects and optical effects,\n",
        "- advanced film processing techniques,\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZodaSbfQeUat"
      },
      "source": [
        "According to the [opencv documentation](https://github.com/opencv/opencv-python#installation-and-usage), only one package `opencv-python` (only main package) or `opencv-contrib-python` (main package + contrib + extra modules) should be installed and on colab there are two so reinstall them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynDMgR_YchuM",
        "outputId": "c45997ba-b327-4736-842d-6850d0120be5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: opencv-python 4.10.0.84\n",
            "Uninstalling opencv-python-4.10.0.84:\n",
            "  Successfully uninstalled opencv-python-4.10.0.84\n",
            "Found existing installation: opencv-contrib-python 4.10.0.84\n",
            "Uninstalling opencv-contrib-python-4.10.0.84:\n",
            "  Successfully uninstalled opencv-contrib-python-4.10.0.84\n",
            "Collecting opencv-contrib-python\n",
            "  Downloading opencv_contrib_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-contrib-python) (1.26.4)\n",
            "Downloading opencv_contrib_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-contrib-python\n",
            "Successfully installed opencv-contrib-python-4.10.0.84\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y opencv-python\n",
        "!pip uninstall -y opencv-contrib-python\n",
        "!pip install opencv-contrib-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMJXpBTXtET5"
      },
      "source": [
        "## Helpers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfiyoH2V2Htn"
      },
      "source": [
        "### Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XE5KwNqA3Ots"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import PIL\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import random\n",
        "\n",
        "from pprint import pprint\n",
        "from ipywidgets import Video\n",
        "\n",
        "from PIL import Image\n",
        "from PIL.ExifTags import TAGS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmmZh-IZ3o43"
      },
      "source": [
        "### Datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFtPC2vud0OR"
      },
      "source": [
        "* a frame from a football match between the Polish and England national teams and a fragment of the frame that will serve as a model for the pattern detection algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePjBbixlqKce",
        "outputId": "efbeddf2-46ea-49ff-9bcd-0673c40bb0ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1D-GbfGKqn982VG43SSB62-PIiv0QXuoZ\n",
            "To: /content/pl_eng.png\n",
            "100% 853k/853k [00:00<00:00, 32.2MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17jZaa3iQO78Bjgk1W3EYBFE7RXKQ7gcM\n",
            "To: /content/template.png\n",
            "100% 19.4k/19.4k [00:00<00:00, 35.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1D-GbfGKqn982VG43SSB62-PIiv0QXuoZ\n",
        "!gdown --id 17jZaa3iQO78Bjgk1W3EYBFE7RXKQ7gcM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig3jR-HLeGpd"
      },
      "source": [
        "* excerpt from a scientific article on generating robot movements based on music of various types ([link](https://www.youtube.com/watch?v=kHBLaw5nfzk)) - the robot is located at the Poznań University of Technology,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3vtJ92X49ky",
        "outputId": "a5fe3f0a-0cf7-46a2-cc4d-e5e7911dfc12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1lJF5LX6m1KbgNGI2pJBQJVgEaU0VdUuF\n",
            "To: /content/anymal_cut.mp4\n",
            "100% 948k/948k [00:00<00:00, 44.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1lJF5LX6m1KbgNGI2pJBQJVgEaU0VdUuF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hOQxINMeLuk"
      },
      "source": [
        "* video from the repository OpenCV,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFn8bChDNYlN",
        "outputId": "12c0c0f5-6957-496c-d7da-0e62018a78f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "slow_traffic_small. 100%[===================>]   1.92M  3.72MB/s    in 0.5s    \n"
          ]
        }
      ],
      "source": [
        "!wget -O slow_traffic_small.mp4 https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4 -q --show-progress"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuNNirnReZSh"
      },
      "source": [
        "* clip of the English League match between Manchester United and Chelsea London."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7umbx6z8Jl3",
        "outputId": "315fa6d7-b487-4595-b8e1-21f223bbd26b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16-H5SnEloiRgnSj_qtKNy0BTkJQZXi6c\n",
            "To: /content/free_kick.mp4\n",
            "100% 510k/510k [00:00<00:00, 54.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 16-H5SnEloiRgnSj_qtKNy0BTkJQZXi6c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3desh1dBMaw"
      },
      "source": [
        "### Visualization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCHL_RVqunsJ"
      },
      "outputs": [],
      "source": [
        "def imshow(a):\n",
        "    a = a.clip(0, 255).astype(\"uint8\")\n",
        "    if a.ndim == 3:\n",
        "        if a.shape[2] == 4:\n",
        "            a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
        "        else:\n",
        "            a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
        "    display(PIL.Image.fromarray(a))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFgmkFPUn3IN"
      },
      "source": [
        "# Video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGu46uq7nn9L"
      },
      "source": [
        "## Background removal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3rNVyf8gJka"
      },
      "source": [
        "Due to the computational requirements, the class of algorithms used in video processing is based on iterative provision of information and its use.\n",
        "\n",
        "One of the most important areas of work on video processing is detailing the background and moving elements.\n",
        "\n",
        "Two iterative background masking algorithms are presented below ([A Duality Based Approach for Realtime TV-L1\n",
        "Optical Flow](https://pequan.lip6.fr/~bereziat/cours/master/vision/papers/zach07.pdf)):\n",
        "- cv2.createBackgroundSubtractorKNN()\n",
        "- cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "These algorithms **learn** from the successive frames of the video, describing the background based on how the pixel and its surroundings have changed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZNdNn4e5LGO",
        "outputId": "b660141c-ed9d-46d2-bd9a-d6bbbe66d05a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video loaded\n",
            "360 640\n",
            "30.0\n"
          ]
        }
      ],
      "source": [
        "anymal = cv2.VideoCapture(\"./anymal_cut.mp4\")\n",
        "if anymal.isOpened():\n",
        "    print(\"Video loaded\")\n",
        "\n",
        "anymal_width = int(anymal.get(3))\n",
        "anymal_height = int(anymal.get(4))\n",
        "\n",
        "print(anymal_height, anymal_width)\n",
        "\n",
        "anymal_fps = anymal.get(cv2.CAP_PROP_FPS)\n",
        "print(anymal_fps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385,
          "referenced_widgets": [
            "20b69667164048219d860e9ebdd156e8",
            "db199e8c80fb4c5a8084ec5de73c73b6"
          ]
        },
        "id": "nw5PyVb3KoKX",
        "outputId": "02cf37d7-9b6e-48dd-c20e-46e9ef8f4203"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20b69667164048219d860e9ebdd156e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Video(value=b'\\x00\\x00\\x00 ftypisom\\x00\\x00\\x02\\x00isomiso2avc1mp41\\x00\\x00\\x00\\x08free\\x00\\x0e1\\x87mdat\\x00\\x…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "Video.from_file(\"anymal_cut.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUbW9OBNvRdT"
      },
      "outputs": [],
      "source": [
        "anymal_foreground_knn = cv2.VideoWriter(\n",
        "    \"anymal_cut_foreground_knn.avi\",\n",
        "    cv2.VideoWriter_fourcc(*\"DIVX\"),\n",
        "    anymal_fps,\n",
        "    (anymal_width, anymal_height),\n",
        "    0,\n",
        ")\n",
        "anymal_foreground_mog2 = cv2.VideoWriter(\n",
        "    \"anymal_cut_foreground_mog2.avi\",\n",
        "    cv2.VideoWriter_fourcc(*\"DIVX\"),\n",
        "    anymal_fps,\n",
        "    (anymal_width, anymal_height),\n",
        "    0,\n",
        ")\n",
        "\n",
        "foreground_knn = cv2.createBackgroundSubtractorKNN()\n",
        "foreground_mog2 = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "anymal.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "while anymal.isOpened():\n",
        "    ret, frame = anymal.read()\n",
        "\n",
        "    if ret:\n",
        "        anymal_foreground_knn.write(foreground_knn.apply(frame))\n",
        "        anymal_foreground_mog2.write(foreground_mog2.apply(frame))\n",
        "    else:\n",
        "        break\n",
        "\n",
        "anymal_foreground_knn.release()\n",
        "anymal_foreground_mog2.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUdogKQRJT1H"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -hide_banner -loglevel error -i anymal_cut_foreground_knn.avi -y anymal_cut_foreground_knn.mp4\n",
        "!ffmpeg -hide_banner -loglevel error -i anymal_cut_foreground_mog2.avi -y anymal_cut_foreground_mog2.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSd8Lhh3EchI"
      },
      "outputs": [],
      "source": [
        "Video.from_file(\"anymal_cut_foreground_knn.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "2de2adc0d9c94f64a70db3c0215e7fc4"
          ]
        },
        "id": "a55Oe7uYK6k4",
        "outputId": "7e0da37e-b677-490a-f2ee-83b89d0541be"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2de2adc0d9c94f64a70db3c0215e7fc4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Video(value=b'\\x00\\x00\\x00 ftypisom\\x00\\x00\\x02\\x00isomiso2avc1mp41\\x00\\x00\\x00\\x08free\\x004R2mdat\\x00\\x00\\x02…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "Video.from_file(\"anymal_cut_foreground_mog2.mp4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aucg-9fcn4EC"
      },
      "source": [
        "## Object tracking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y02V2GeNgPx2"
      },
      "source": [
        "In addition to the separation of static and dynamic elements from the background, one can also distinguish a class of object tracking algorithms.\n",
        "\n",
        "A big disadvantage of classic algorithms in this field is **the requirement to indicate the element that we want to track**. These algorithms only implement a tracking function, not a detection function.\n",
        "\n",
        "The basic algorithms include:\n",
        "- mean shift - an iterative algorithm that checks matches in the immediate vicinity of the current match and moves towards the best neighbor,\n",
        "- cam shift - modification of the mean shift algorithm, which also adjusts the environment (window / bounding box) in subsequent steps,\n",
        "- more advanced, also with the training phase:\n",
        "  - Boosting,\n",
        "  - MIL,\n",
        "  - KCF,\n",
        "  - TLF,\n",
        "  - MedianFlow,\n",
        "  - MOSSE,\n",
        "  - CSRT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cW_Om5CqNrYP",
        "outputId": "f5ab15ff-1790-4798-8cfc-8e49fb1225d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video loaded\n",
            "360 640\n",
            "29.97002997002997\n"
          ]
        }
      ],
      "source": [
        "traffic = cv2.VideoCapture(\"./slow_traffic_small.mp4\")\n",
        "if traffic.isOpened():\n",
        "    print(\"Video loaded\")\n",
        "\n",
        "traffic_width = int(traffic.get(3))\n",
        "traffic_height = int(traffic.get(4))\n",
        "\n",
        "print(traffic_height, traffic_width)\n",
        "\n",
        "traffic_fps = traffic.get(cv2.CAP_PROP_FPS)\n",
        "print(traffic_fps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "857e443945e04b8899497dd7470d2f8e"
          ]
        },
        "id": "0D88r2ZJNthK",
        "outputId": "440b3d88-b6b5-4a6a-f868-2d373e60bf6f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "857e443945e04b8899497dd7470d2f8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Video(value=b'\\x00\\x00\\x00 ftypisom\\x00\\x00\\x02\\x00isomiso2avc1mp41\\x00\\x00\\x00\\x08free\\x00\\x1eD\\xe4mdat\\x00\\x…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "Video.from_file(\"./slow_traffic_small.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E2yRx3LWvzkX"
      },
      "outputs": [],
      "source": [
        "traffic.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "ret, frame = traffic.read()\n",
        "x, y, w, h = 300, 200, 100, 50  # simply hardcoded the values\n",
        "track_window = (x, y, w, h)\n",
        "roi = frame[y : y + h, x : x + w]\n",
        "\n",
        "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
        "mask = cv2.inRange(\n",
        "    hsv_roi, np.array((0.0, 60.0, 32.0)), np.array((180.0, 255.0, 255.0))\n",
        ")\n",
        "roi_hist = cv2.calcHist([hsv_roi], [0], mask, [180], [0, 180])\n",
        "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
        "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTBMSEFtOXQf"
      },
      "outputs": [],
      "source": [
        "traffic_track = cv2.VideoWriter(\n",
        "    \"./slow_traffic_small_meanshift.avi\",\n",
        "    cv2.VideoWriter_fourcc(*\"DIVX\"),\n",
        "    traffic_fps,\n",
        "    (traffic_width, traffic_height),\n",
        ")\n",
        "\n",
        "traffic.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "while traffic.isOpened():\n",
        "    ret, frame = traffic.read()\n",
        "\n",
        "    if ret:\n",
        "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "        dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
        "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
        "        x, y, w, h = track_window\n",
        "        traffic_track.write(cv2.rectangle(frame, (x, y), (x + w, y + h), 255, 2))\n",
        "    else:\n",
        "        break\n",
        "\n",
        "traffic_track.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JNA1qBNPDyo"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -hide_banner -loglevel error -i slow_traffic_small_meanshift.avi -y slow_traffic_small_meanshift.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDvqTjVDPSqK"
      },
      "outputs": [],
      "source": [
        "Video.from_file(\"./slow_traffic_small_meanshift.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kO_88IOkv38c"
      },
      "outputs": [],
      "source": [
        "traffic.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "ret, frame = traffic.read()\n",
        "x, y, w, h = 300, 200, 100, 50  # simply hardcoded the values\n",
        "track_window = (x, y, w, h)\n",
        "roi = frame[y : y + h, x : x + w]\n",
        "\n",
        "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
        "mask = cv2.inRange(\n",
        "    hsv_roi, np.array((0.0, 60.0, 32.0)), np.array((180.0, 255.0, 255.0))\n",
        ")\n",
        "roi_hist = cv2.calcHist([hsv_roi], [0], mask, [180], [0, 180])\n",
        "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
        "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CEw_-Y4QFjB"
      },
      "outputs": [],
      "source": [
        "traffic_track = cv2.VideoWriter(\n",
        "    \"./slow_traffic_small_camshift.avi\",\n",
        "    cv2.VideoWriter_fourcc(*\"DIVX\"),\n",
        "    traffic_fps,\n",
        "    (traffic_width, traffic_height),\n",
        ")\n",
        "\n",
        "traffic.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "while traffic.isOpened():\n",
        "    ret, frame = traffic.read()\n",
        "\n",
        "    if ret:\n",
        "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "        dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
        "        ret, track_window = cv2.CamShift(dst, track_window, term_crit)\n",
        "        pts = np.int0(cv2.boxPoints(ret))\n",
        "        traffic_track.write(cv2.polylines(frame, [pts], True, 255, 2))\n",
        "    else:\n",
        "        break\n",
        "\n",
        "traffic_track.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8nCB5I9QmU-"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -hide_banner -loglevel error -i slow_traffic_small_camshift.avi -y slow_traffic_small_camshift.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18SZlGLlQnng"
      },
      "outputs": [],
      "source": [
        "Video.from_file(\"./slow_traffic_small_camshift.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4_5VaeV9tWt"
      },
      "outputs": [],
      "source": [
        "free_kick = cv2.VideoCapture(\"free_kick.mp4\")\n",
        "if free_kick.isOpened():\n",
        "    print(\"Video loaded\")\n",
        "\n",
        "free_kick_width = int(free_kick.get(3))\n",
        "free_kick_height = int(free_kick.get(4))\n",
        "\n",
        "print(free_kick_height, free_kick_width)\n",
        "\n",
        "free_kick_fps = free_kick.get(cv2.CAP_PROP_FPS)\n",
        "print(free_kick_fps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGl4KGOD_7-k"
      },
      "outputs": [],
      "source": [
        "def create_tracker(tracker_type):\n",
        "    tracker_types = [\n",
        "        \"BOOSTING\",\n",
        "        \"MIL\",\n",
        "        \"KCF\",\n",
        "        \"TLD\",\n",
        "        \"MEDIANFLOW\",\n",
        "        \"MOSSE\",\n",
        "        \"CSRT\",\n",
        "    ]\n",
        "    if tracker_type == 'BOOSTING':\n",
        "        tracker = cv2.legacy.TrackerBoosting_create()\n",
        "    if tracker_type == 'MIL':\n",
        "        tracker = cv2.TrackerMIL_create()\n",
        "    if tracker_type == 'KCF':\n",
        "        tracker = cv2.TrackerKCF_create()\n",
        "    if tracker_type == 'TLD':\n",
        "        tracker = cv2.legacy.TrackerTLD_create()\n",
        "    if tracker_type == 'MEDIANFLOW':\n",
        "        tracker = cv2.legacy.TrackerMedianFlow_create()\n",
        "    if tracker_type == 'MOSSE':\n",
        "        tracker = cv2.legacy.TrackerMOSSE_create()\n",
        "    if tracker_type == \"CSRT\":\n",
        "        tracker = cv2.TrackerCSRT_create()\n",
        "\n",
        "def draw_bbox(frame, bbox, color=(255, 255, 255)):\n",
        "    p1 = (int(bbox[0]), int(bbox[1]))\n",
        "    p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
        "    cv2.rectangle(frame, p1, p2, color, 2, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOEZDH_QBv2M"
      },
      "outputs": [],
      "source": [
        "free_kick.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "ret, frame = free_kick.read()\n",
        "\n",
        "player_bbox = (190, 260, 70, 100)\n",
        "gkeeper_bbox = (375, 55, 60, 80)\n",
        "\n",
        "draw_bbox(frame, player_bbox, (255, 0, 0))\n",
        "draw_bbox(frame, gkeeper_bbox, (255, 255, 0))\n",
        "\n",
        "imshow(frame)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91MiRXGwvTy8"
      },
      "outputs": [],
      "source": [
        "free_kick.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "ret, frame = free_kick.read()\n",
        "\n",
        "player_bbox = (190, 260, 70, 100)\n",
        "gkeeper_bbox = (375, 55, 60, 80)\n",
        "\n",
        "player_tracker = create_tracker(\"CSRT\")\n",
        "gkeeper_tracker = create_tracker(\"CSRT\")\n",
        "\n",
        "if player_tracker.init(frame, player_bbox):\n",
        "    print(\"Player tracking algorithm initiated at point:\", player_bbox)\n",
        "\n",
        "if gkeeper_tracker.init(frame, gkeeper_bbox):\n",
        "    print(\"Goalkeeper tracking algorithm initiated at point:\", gkeeper_bbox)\n",
        "\n",
        "free_kick_track = cv2.VideoWriter(\n",
        "    \"./free_kick_track.avi\",\n",
        "    cv2.VideoWriter_fourcc(*\"DIVX\"),\n",
        "    free_kick_fps,\n",
        "    (free_kick_width, free_kick_height),\n",
        ")\n",
        "\n",
        "free_kick.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "while free_kick.isOpened():\n",
        "    ret, frame = free_kick.read()\n",
        "\n",
        "    if ret:\n",
        "        ok, bbox = player_tracker.update(frame)\n",
        "        if ok:\n",
        "            draw_bbox(frame, bbox, (0, 255, 0))\n",
        "\n",
        "        ok, bbox = gkeeper_tracker.update(frame)\n",
        "        if ok:\n",
        "            draw_bbox(frame, bbox, (0, 255, 0))\n",
        "\n",
        "        free_kick_track.write(frame)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "free_kick_track.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rpU9V9T-Ge2"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -hide_banner -loglevel error -i free_kick_track.avi -y free_kick_track.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5R8wqKJF-J8Y"
      },
      "outputs": [],
      "source": [
        "Video.from_file(\"./free_kick_track.mp4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6AKfHqCoLMh"
      },
      "source": [
        "## Optical flow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1P_KPC7gsqh"
      },
      "source": [
        "Object tracking requires that you recognize and know some kind of object that you want to track. For example, by following the players on the pitch, we know what they look like (we have a pattern). The general case of object tracking is optical motion tracking.\n",
        "\n",
        "For example, a soccer player can move forward. In the event that it is an attempt to kick the ball, the footballer will likely make a hand movement. Both the player (as an object) moved one way and the hands (as sub-objects) moved the other way.\n",
        "\n",
        "Optical motion tracking goes even lower and analyzes the pixels and their surroundings, firstly identifying characteristic points in the image and secondly tracking them as separate objects.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "945WzZw0IxS7"
      },
      "outputs": [],
      "source": [
        "traffic = cv2.VideoCapture(\"./slow_traffic_small.mp4\")\n",
        "if traffic.isOpened():\n",
        "    print(\"Video loaded!\")\n",
        "\n",
        "traffic_width = int(traffic.get(3))\n",
        "traffic_height = int(traffic.get(4))\n",
        "\n",
        "print(traffic_height, traffic_width)\n",
        "\n",
        "traffic_fps = traffic.get(cv2.CAP_PROP_FPS)\n",
        "print(traffic_fps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1ilusSIIzuV"
      },
      "outputs": [],
      "source": [
        "Video.from_file(\"./slow_traffic_small.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vd6LiqQXJCGK"
      },
      "outputs": [],
      "source": [
        "feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
        "lk_params = dict(\n",
        "    winSize=(15, 15),\n",
        "    maxLevel=2,\n",
        "    criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),\n",
        ")\n",
        "# Create some random colors\n",
        "color = np.random.randint(0, 255, (100, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSOsX5ZOJYCQ"
      },
      "outputs": [],
      "source": [
        "traffic.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "ret, old_frame = traffic.read()\n",
        "\n",
        "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
        "mask = np.zeros_like(old_frame)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wn1-LIxMI3yD"
      },
      "outputs": [],
      "source": [
        "traffic_optical_flow = cv2.VideoWriter(\n",
        "    \"./slow_traffic_small_optical_flow.avi\",\n",
        "    cv2.VideoWriter_fourcc(*\"DIVX\"),\n",
        "    traffic_fps,\n",
        "    (traffic_width, traffic_height),\n",
        ")\n",
        "\n",
        "traffic.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "while traffic.isOpened():\n",
        "    ret, frame = traffic.read()\n",
        "\n",
        "    if ret:\n",
        "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        p1, st, err = cv2.calcOpticalFlowPyrLK(\n",
        "            old_gray, frame_gray, p0, None, **lk_params\n",
        "        )\n",
        "        if p1 is not None:\n",
        "            good_new = p1[st == 1]\n",
        "            good_old = p0[st == 1]\n",
        "\n",
        "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "            a, b = new.ravel()\n",
        "            c, d = old.ravel()\n",
        "            mask = cv2.line(\n",
        "                mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2\n",
        "            )\n",
        "            frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
        "\n",
        "        old_gray = frame_gray.copy()\n",
        "        p0 = good_new.reshape(-1, 1, 2)\n",
        "\n",
        "        traffic_optical_flow.write(cv2.add(frame, mask))\n",
        "    else:\n",
        "        break\n",
        "\n",
        "traffic_optical_flow.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzpqG4n7Kh4W"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -hide_banner -loglevel error -i slow_traffic_small_optical_flow.avi -y slow_traffic_small_optical_flow.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xS-U4FlQKl3-"
      },
      "outputs": [],
      "source": [
        "Video.from_file(\"./slow_traffic_small_optical_flow.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7KSAypBDudN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "20b69667164048219d860e9ebdd156e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VideoModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VideoModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VideoView",
            "autoplay": true,
            "controls": true,
            "format": "mp4",
            "height": "",
            "layout": "IPY_MODEL_db199e8c80fb4c5a8084ec5de73c73b6",
            "loop": true,
            "width": ""
          }
        },
        "db199e8c80fb4c5a8084ec5de73c73b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}